{
    "measurement_set.TestLoadProcessingSet.time_basic_load": {
        "code": "class TestLoadProcessingSet:\n    def time_basic_load(self):\n        \"\"\"Test basic loading of processing set without parameters\"\"\"\n        ps_xdt = load_processing_set(self.processing_set)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/unit/measurement_set/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_basic_load",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:29",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_check_datatree": {
        "code": "class TestLoadProcessingSet:\n    def time_check_datatree(self):\n        \"\"\"Test that the converted MS to PS complies with the datatree schema checker\"\"\"\n        ps_xdt = load_processing_set(self.processing_set)\n        issues = check_datatree(ps_xdt)\n        # The check_datatree function returns a SchemaIssues object, not a string\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/unit/measurement_set/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_check_datatree",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:29",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_data_group_selection": {
        "code": "class TestLoadProcessingSet:\n    def time_data_group_selection(self):\n        \"\"\"Test loading with specific data group\"\"\"\n        ps_xdt = load_processing_set(self.processing_set, data_group_name=\"base\")\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/unit/measurement_set/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_data_group_selection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:29",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_drop_variable": {
        "code": "class TestLoadProcessingSet:\n    def time_drop_variable(self):\n        \"\"\"Test loading with specific variables dropped\"\"\"\n        # Test dropping specific variable\n        drop_vars = [\"WEIGHT\"]\n        ps_xdt = load_processing_set(self.processing_set, drop_variables=drop_vars)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/unit/measurement_set/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_drop_variable",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:29",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_include_variable": {
        "code": "class TestLoadProcessingSet:\n    def time_include_variable(self):\n        \"\"\"Test loading with specific variables included\"\"\"\n        # Test including specific variable\n        include_vars = [\"VISIBILITY\"]\n        ps_xdt = load_processing_set(\n            self.processing_set,\n            include_variables=include_vars,\n        )\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/unit/measurement_set/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_include_variable",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:29",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_selective_loading": {
        "code": "class TestLoadProcessingSet:\n    def time_selective_loading(self):\n        \"\"\"Test loading with selection parameters\"\"\"\n        # First load normally to get MS names\n        full_ps = load_processing_set(self.processing_set)\n    \n        # Check MS names are the expected ones\n        ms_basename = \"Antennae_North.cal.lsrk.split\"\n        expected_names = [f\"{ms_basename}_{i}\" for i in range(4)]  # 0 to 3\n        ms_names = list(full_ps.children.keys())\n    \n        assert len(ms_names) == len(\n            expected_names\n        ), \"Number of measurement sets doesn't match\"\n        for ms_name, expected_name in zip(sorted(ms_names), sorted(expected_names)):\n            assert (\n                ms_name == expected_name\n            ), f\"Expected {expected_name} but got {ms_name}\"\n    \n        # Test loading with selection parameters\n        sel_parms = {ms_name: {\"time\": slice(0, 10)}}\n        ps_xdt = load_processing_set(self.processing_set, sel_parms=sel_parms)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/unit/measurement_set/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_selective_loading",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:29",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_sub_datasets_false": {
        "code": "class TestLoadProcessingSet:\n    def time_sub_datasets_false(self):\n        \"\"\"Test loading without sub-datasets\"\"\"\n        # Test without sub-datasets\n        ps_without_subs = load_processing_set(\n            self.processing_set, load_sub_datasets=False\n        )\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/unit/measurement_set/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_sub_datasets_false",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:29",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_sub_datasets_true": {
        "code": "class TestLoadProcessingSet:\n    def time_sub_datasets_true(self):\n        \"\"\"Test loading with sub-datasets\"\"\"\n        # Test with sub-datasets\n        _ps_with_subs = load_processing_set(self.processing_set, load_sub_datasets=True)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/unit/measurement_set/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_sub_datasets_true",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:29",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestMeasurementSetXdtWithData.time_add_data_group_with_defaults": {
        "code": "class TestMeasurementSetXdtWithData:\n    def time_add_data_group_with_defaults(self, _msv4_xdt):\n        \"\"\"Benchmark adding a data group with defaults\"\"\"\n        self.ms_xdt.add_data_group(\"test_added_data_group_with_defaults\")\n\n    def setup(self, msv4_xdt):\n        # Store the cached MSv4 XDT\n        self.msv4_xdt = msv4_xdt\n        self.ms_xdt = self.msv4_xdt.xr_ms\n\n    def setup_cache(self):\n        ms_path, _ = gen_minimal_ms()\n        msv4_path = build_minimal_msv4_xdt(\n            ms_path,\n            partition_kwargs={\n                \"DATA_DESC_ID\": [0],\n                \"OBS_MODE\": [\"CAL_ATMOSPHERE#ON_SOURCE\"],\n            },\n        )\n        return xr.open_datatree(msv4_path, engine=\"zarr\")",
        "min_run_count": 2,
        "name": "measurement_set.TestMeasurementSetXdtWithData.time_add_data_group_with_defaults",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:267",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestMeasurementSetXdtWithData.time_add_data_group_with_values": {
        "code": "class TestMeasurementSetXdtWithData:\n    def time_add_data_group_with_values(self, _msv4_xdt):\n        \"\"\"Benchmark adding a data group with parameter values\"\"\"\n        self.ms_xdt.add_data_group(\n            \"test_added_data_group_with_param_values\",\n            {\n                \"correlated_data\":\"VISIBILITY\",\n                \"weight\":\"EFFECTIVE_INTEGRATION_TIME\",\n                \"flag\":\"FLAG\",\n                \"uvw\":\"UVW\",\n                \"field_and_source_xds\":\"field_and_source_base_xds\",\n                \"date_time\":\"today, now\",\n                \"description\":\"a test data group\",\n            },\n            data_group_dv_shared_with=\"base\",\n        )\n\n    def setup(self, msv4_xdt):\n        # Store the cached MSv4 XDT\n        self.msv4_xdt = msv4_xdt\n        self.ms_xdt = self.msv4_xdt.xr_ms\n\n    def setup_cache(self):\n        ms_path, _ = gen_minimal_ms()\n        msv4_path = build_minimal_msv4_xdt(\n            ms_path,\n            partition_kwargs={\n                \"DATA_DESC_ID\": [0],\n                \"OBS_MODE\": [\"CAL_ATMOSPHERE#ON_SOURCE\"],\n            },\n        )\n        return xr.open_datatree(msv4_path, engine=\"zarr\")",
        "min_run_count": 2,
        "name": "measurement_set.TestMeasurementSetXdtWithData.time_add_data_group_with_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:267",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestMeasurementSetXdtWithData.time_get_field_and_source_xds": {
        "code": "class TestMeasurementSetXdtWithData:\n    def time_get_field_and_source_xds(self, _msv4_xdt):\n        \"\"\"Benchmark getting field and source XDS\"\"\"\n        self.ms_xdt.get_field_and_source_xds()\n\n    def setup(self, msv4_xdt):\n        # Store the cached MSv4 XDT\n        self.msv4_xdt = msv4_xdt\n        self.ms_xdt = self.msv4_xdt.xr_ms\n\n    def setup_cache(self):\n        ms_path, _ = gen_minimal_ms()\n        msv4_path = build_minimal_msv4_xdt(\n            ms_path,\n            partition_kwargs={\n                \"DATA_DESC_ID\": [0],\n                \"OBS_MODE\": [\"CAL_ATMOSPHERE#ON_SOURCE\"],\n            },\n        )\n        return xr.open_datatree(msv4_path, engine=\"zarr\")",
        "min_run_count": 2,
        "name": "measurement_set.TestMeasurementSetXdtWithData.time_get_field_and_source_xds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:267",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestMeasurementSetXdtWithData.time_get_field_and_source_xds_with_group": {
        "code": "class TestMeasurementSetXdtWithData:\n    def time_get_field_and_source_xds_with_group(self, _msv4_xdt):\n        \"\"\"Benchmark getting field and source XDS with data group\"\"\"\n        self.ms_xdt.get_field_and_source_xds(data_group_name=\"base\")\n\n    def setup(self, msv4_xdt):\n        # Store the cached MSv4 XDT\n        self.msv4_xdt = msv4_xdt\n        self.ms_xdt = self.msv4_xdt.xr_ms\n\n    def setup_cache(self):\n        ms_path, _ = gen_minimal_ms()\n        msv4_path = build_minimal_msv4_xdt(\n            ms_path,\n            partition_kwargs={\n                \"DATA_DESC_ID\": [0],\n                \"OBS_MODE\": [\"CAL_ATMOSPHERE#ON_SOURCE\"],\n            },\n        )\n        return xr.open_datatree(msv4_path, engine=\"zarr\")",
        "min_run_count": 2,
        "name": "measurement_set.TestMeasurementSetXdtWithData.time_get_field_and_source_xds_with_group",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:267",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestMeasurementSetXdtWithData.time_get_partition_info_default": {
        "code": "class TestMeasurementSetXdtWithData:\n    def time_get_partition_info_default(self, _msv4_xdt):\n        \"\"\"Benchmark getting partition info with defaults\"\"\"\n        self.ms_xdt.get_partition_info()\n\n    def setup(self, msv4_xdt):\n        # Store the cached MSv4 XDT\n        self.msv4_xdt = msv4_xdt\n        self.ms_xdt = self.msv4_xdt.xr_ms\n\n    def setup_cache(self):\n        ms_path, _ = gen_minimal_ms()\n        msv4_path = build_minimal_msv4_xdt(\n            ms_path,\n            partition_kwargs={\n                \"DATA_DESC_ID\": [0],\n                \"OBS_MODE\": [\"CAL_ATMOSPHERE#ON_SOURCE\"],\n            },\n        )\n        return xr.open_datatree(msv4_path, engine=\"zarr\")",
        "min_run_count": 2,
        "name": "measurement_set.TestMeasurementSetXdtWithData.time_get_partition_info_default",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:267",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestMeasurementSetXdtWithData.time_get_partition_info_with_group": {
        "code": "class TestMeasurementSetXdtWithData:\n    def time_get_partition_info_with_group(self, _msv4_xdt):\n        \"\"\"Benchmark getting partition info with data group\"\"\"\n        self.ms_xdt.get_partition_info(data_group_name=\"base\")\n\n    def setup(self, msv4_xdt):\n        # Store the cached MSv4 XDT\n        self.msv4_xdt = msv4_xdt\n        self.ms_xdt = self.msv4_xdt.xr_ms\n\n    def setup_cache(self):\n        ms_path, _ = gen_minimal_ms()\n        msv4_path = build_minimal_msv4_xdt(\n            ms_path,\n            partition_kwargs={\n                \"DATA_DESC_ID\": [0],\n                \"OBS_MODE\": [\"CAL_ATMOSPHERE#ON_SOURCE\"],\n            },\n        )\n        return xr.open_datatree(msv4_path, engine=\"zarr\")",
        "min_run_count": 2,
        "name": "measurement_set.TestMeasurementSetXdtWithData.time_get_partition_info_with_group",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:267",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestMeasurementSetXdtWithData.time_sel_polarization": {
        "code": "class TestMeasurementSetXdtWithData:\n    def time_sel_polarization(self, _msv4_xdt):\n        \"\"\"Benchmark selecting with polarization\"\"\"\n        self.ms_xdt.sel(polarization=\"XX\")\n\n    def setup(self, msv4_xdt):\n        # Store the cached MSv4 XDT\n        self.msv4_xdt = msv4_xdt\n        self.ms_xdt = self.msv4_xdt.xr_ms\n\n    def setup_cache(self):\n        ms_path, _ = gen_minimal_ms()\n        msv4_path = build_minimal_msv4_xdt(\n            ms_path,\n            partition_kwargs={\n                \"DATA_DESC_ID\": [0],\n                \"OBS_MODE\": [\"CAL_ATMOSPHERE#ON_SOURCE\"],\n            },\n        )\n        return xr.open_datatree(msv4_path, engine=\"zarr\")",
        "min_run_count": 2,
        "name": "measurement_set.TestMeasurementSetXdtWithData.time_sel_polarization",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:267",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestMeasurementSetXdtWithData.time_sel_with_data_group": {
        "code": "class TestMeasurementSetXdtWithData:\n    def time_sel_with_data_group(self, _msv4_xdt):\n        \"\"\"Benchmark selecting with data group\"\"\"\n        self.ms_xdt.sel(data_group_name=\"base\")\n\n    def setup(self, msv4_xdt):\n        # Store the cached MSv4 XDT\n        self.msv4_xdt = msv4_xdt\n        self.ms_xdt = self.msv4_xdt.xr_ms\n\n    def setup_cache(self):\n        ms_path, _ = gen_minimal_ms()\n        msv4_path = build_minimal_msv4_xdt(\n            ms_path,\n            partition_kwargs={\n                \"DATA_DESC_ID\": [0],\n                \"OBS_MODE\": [\"CAL_ATMOSPHERE#ON_SOURCE\"],\n            },\n        )\n        return xr.open_datatree(msv4_path, engine=\"zarr\")",
        "min_run_count": 2,
        "name": "measurement_set.TestMeasurementSetXdtWithData.time_sel_with_data_group",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:267",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_get_combined_antenna_xds": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_get_combined_antenna_xds(self, ps_xdt):\n        \"\"\"Benchmark getting combined antenna dataset from a processing set\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_combined_antenna_xds()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_get_combined_antenna_xds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:131",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_get_combined_field_and_source_xds": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_get_combined_field_and_source_xds(self, ps_xdt):\n        \"\"\"Benchmark getting combined field and source dataset from a processing set\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_combined_field_and_source_xds()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_get_combined_field_and_source_xds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:131",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_get_freq_axis": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_get_freq_axis(self, ps_xdt):\n        \"\"\"Benchmark getting frequency axis from a processing set\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_freq_axis()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_get_freq_axis",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:131",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_get_max_dims": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_get_max_dims(self, ps_xdt):\n        \"\"\"Benchmark getting maximum dimensions from a processing set\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_max_dims()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_get_max_dims",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:131",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_query_by_data_group": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_query_by_data_group(self, ps_xdt):\n        \"\"\"Benchmark querying a processing set by data group\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.query(data_group_name=\"base\")\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_query_by_data_group",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:131",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_query_by_name": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_query_by_name(self, ps_xdt):\n        \"\"\"Benchmark querying a processing set by name\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        ms_names = list(ps_xdt.children.keys())\n        ps_xdt.xr_ps.query(name=ms_names[0])\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_query_by_name",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:131",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_summary": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_summary(self, ps_xdt):\n        \"\"\"Benchmark the summary method on a real processing set\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.summary()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_summary",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:131",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_summary_ordered": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_summary_ordered(self, ps_xdt):\n        \"\"\"Benchmark the summary method with first_columns parameter\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.summary(first_columns=[\"spw_name\", \"scan_name\"])\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_summary_ordered",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:131",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithEphemerisData.time_check_datatree": {
        "code": "class TestProcessingSetXdtWithEphemerisData:\n    def time_check_datatree(self, ps_xdt):\n        \"\"\"Benchmark that the converted MS to PS complies with the datatree schema checker\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        check_datatree(ps_xdt)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithEphemerisData.time_check_datatree",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:214",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithEphemerisData.time_get_combined_field_and_source_xds_ephemeris": {
        "code": "class TestProcessingSetXdtWithEphemerisData:\n    def time_get_combined_field_and_source_xds_ephemeris(self, ps_xdt):\n        \"\"\"Benchmark getting combined field and source dataset with ephemeris from a processing set\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_combined_field_and_source_xds_ephemeris()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithEphemerisData.time_get_combined_field_and_source_xds_ephemeris",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:214",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithEphemerisData.time_time_interpolation": {
        "code": "class TestProcessingSetXdtWithEphemerisData:\n    def time_time_interpolation(self, ps_xdt):\n        \"\"\"Benchmark that time interpolation works correctly for ephemeris data\"\"\"\n        # ps_xdt = load_processing_set(self.processing_set)\n        field_source_xds = ps_xdt.xr_ps.get_combined_field_and_source_xds_ephemeris()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # originally adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        ms_path = download_measurement_set(self.MeasurementSet)\n    \n        # Convert MS to processing set\n        ps_path = self.processing_set\n    \n        build_processing_set_from_msv2(\n            in_file=ms_path,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            persistence_mode=\"w\",\n            parallel_mode=\"none\",\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithEphemerisData.time_time_interpolation",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:214",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array": {
        "code": "class TestSchema:\n    def time_check_array(self):\n        data = numpy.zeros(10, dtype=complex)\n        coords = [(\"coord\", numpy.arange(10, dtype=float))]\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345}\n        array = xarray.DataArray(data, coords, attrs=attrs)\n        check_array(array, TEST_ARRAY_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_constructor_array_style": {
        "code": "class TestSchema:\n    def time_check_array_constructor_array_style(self):\n        data = numpy.zeros(10, dtype=complex)\n        coords = [(\"coord\", numpy.arange(10, dtype=float))]\n        attrs = {\"attr1\": \"str\", \"attr2\": 1234, \"attr3\": 345}\n        array = _TestArraySchema(data=data, coords=coords, attrs=attrs)\n        check_array(array, TEST_ARRAY_SCHEMA).expect()\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_constructor_array_style",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_constructor_auto_coords": {
        "code": "class TestSchema:\n    def time_check_array_constructor_auto_coords(self):\n        array = _TestArraySchema(\n            data=numpy.zeros(10, dtype=complex), attr1=\"str\", attr2=1234, attr3=345\n        )\n        check_array(array, TEST_ARRAY_SCHEMA).expect()\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_constructor_auto_coords",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_constructor_dataclass_style": {
        "code": "class TestSchema:\n    def time_check_array_constructor_dataclass_style(self):\n        array = _TestArraySchema(\n            data=numpy.zeros(10, dtype=complex),\n            coord=numpy.arange(10, dtype=float),\n            attr1=\"str\",\n            attr2=1234,\n            attr3=345,\n        )\n        check_array(array, TEST_ARRAY_SCHEMA).expect()\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_constructor_dataclass_style",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_constructor_defaults": {
        "code": "class TestSchema:\n    def time_check_array_constructor_defaults(self):\n        array = _TestArraySchema(\n            numpy.zeros(10, dtype=complex),\n            numpy.arange(10, dtype=float),\n            \"str\",\n        )\n        check_array(array, TEST_ARRAY_SCHEMA).expect()\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_constructor_defaults",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_constructor_from_dataarray": {
        "code": "class TestSchema:\n    def time_check_array_constructor_from_dataarray(self):\n        data = numpy.zeros(10, dtype=complex)\n        coords = [(\"coord\", numpy.arange(10, dtype=float))]\n        attrs = {\"attr1\": \"str\", \"attr2\": 1234, \"attr3\": 345}\n        array = xarray.DataArray(data, coords, attrs=attrs)\n        array = _TestArraySchema(array)\n        check_array(array, TEST_ARRAY_SCHEMA).expect()\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_constructor_from_dataarray",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_constructor_from_dataarray_override": {
        "code": "class TestSchema:\n    def time_check_array_constructor_from_dataarray_override(self):\n        data = numpy.zeros(10, dtype=complex)\n        coords = [(\"coord\", numpy.arange(10, dtype=float))]\n        attrs = {\"attr1\": \"str\", \"attr2\": 1234, \"attr3\": 345}\n        array = xarray.DataArray(data, coords, attrs=attrs)\n        array = _TestArraySchema(\n            data=array,\n            coords=[(\"coord\", 1 + numpy.arange(10, dtype=float))],\n            attrs={\"attr1\": \"strstr\", \"attr2\": 12345},\n        )\n        check_array(array, TEST_ARRAY_SCHEMA).expect()\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_constructor_from_dataarray_override",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_constructor_list": {
        "code": "class TestSchema:\n    def time_check_array_constructor_list(self):\n        array = _TestArraySchema(\n            data=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            coord=(\"coord\", [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], {\"asd\": \"foo\"}),\n            attr1=\"str\",\n            attr2=1234,\n            attr3=345,\n        )\n        check_array(array, TEST_ARRAY_SCHEMA).expect()\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_constructor_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_constructor_mixed": {
        "code": "class TestSchema:\n    def time_check_array_constructor_mixed(self):\n        array = _TestArraySchema(\n            numpy.zeros(10, dtype=complex),\n            attr1=\"str\",\n            coords={\n                \"coord\": numpy.arange(10, dtype=float),\n            },\n            attrs={\n                \"attr2\": 123,\n            },\n        )\n        check_array(array, TEST_ARRAY_SCHEMA).expect()\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_constructor_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_dask": {
        "code": "class TestSchema:\n    def time_check_array_dask(self):\n        data = dask.array.zeros(10, dtype=complex)\n        coords = [(\"coord\", numpy.arange(10, dtype=float))]\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345}\n        array = xarray.DataArray(data, coords, attrs=attrs)\n        check_array(array, TEST_ARRAY_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_dask",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_extra_attr": {
        "code": "class TestSchema:\n    def time_check_array_extra_attr(self):\n        data = numpy.zeros(10, dtype=complex)\n        coords = [(\"coord\", numpy.arange(10, dtype=float))]\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345, \"attr4\": \"asd\"}\n        array = xarray.DataArray(data, coords, attrs=attrs)\n        check_array(array, TEST_ARRAY_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_extra_attr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_extra_coord": {
        "code": "class TestSchema:\n    def time_check_array_extra_coord(self):\n        coords2 = [\n            (\"coord\", numpy.arange(10, dtype=float)),\n            (\"coord2\", numpy.arange(1, dtype=float)),\n        ]\n        data2 = numpy.zeros(10, dtype=complex)[:, numpy.newaxis]\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345}\n        check_array(\n            xarray.DataArray(data2, coords2, attrs=attrs), TEST_ARRAY_SCHEMA\n        )\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_extra_coord",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_missing_coord": {
        "code": "class TestSchema:\n    def time_check_array_missing_coord(self):\n        data0 = numpy.array(None, dtype=complex)\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345}\n        check_array(xarray.DataArray(data0, {}, attrs=attrs), TEST_ARRAY_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_missing_coord",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_array_optional_attr": {
        "code": "class TestSchema:\n    def time_check_array_optional_attr(self):\n        data = numpy.zeros(10, dtype=complex)\n        coords = [(\"coord\", numpy.arange(10, dtype=float))]\n        attrs = {\"attr1\": \"str\", \"attr2\": 123}\n        array = xarray.DataArray(data, coords, attrs=attrs)\n        check_array(array, TEST_ARRAY_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_array_optional_attr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_dataset": {
        "code": "class TestSchema:\n    def time_check_dataset(self):\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345}\n        coords = {\n            \"coord\": xarray.DataArray(\n                numpy.arange(10, dtype=float), dims=(\"coord\",), attrs=attrs\n            ),\n            \"coord2\": numpy.arange(5, dtype=int),\n        }\n        data_vars = {\n            \"data_var\": (\"coord\", numpy.zeros(10, dtype=complex), attrs),\n            \"data_var_simple\": (\"coord2\", numpy.zeros(5, dtype=numpy.float32)),\n        }\n        dataset = xarray.Dataset(data_vars, coords, attrs)\n        check_dataset(dataset, TEST_DATASET_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_dataset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_dataset_constructor_auto_coords": {
        "code": "class TestSchema:\n    def time_check_dataset_constructor_auto_coords(self):\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345}\n        dataset = _TestDatasetSchema(\n            data_var=_TestArraySchema(\n                dask.array.zeros(10, dtype=complex),\n                dims=(\"coord\",),\n                coord=xarray.DataArray(\n                    numpy.arange(10, dtype=float), dims=(\"coord\",), attrs=attrs\n                ),\n                attrs=attrs,\n            ),\n            coord=xarray.DataArray(\n                numpy.arange(10, dtype=float), dims=(\"coord\",), attrs=attrs\n            ),\n            data_var_simple=(\"coord2\", dask.array.zeros(25, dtype=numpy.float32)),\n            attr1=\"str\",\n            attr2=123,\n            attr3=345,\n        )\n        issues = check_dataset(dataset, TEST_DATASET_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_dataset_constructor_auto_coords",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_dataset_extra_datavar": {
        "code": "class TestSchema:\n    def time_check_dataset_extra_datavar(self):\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345}\n        coords = {\n            \"coord2\": numpy.arange(5, dtype=int),\n            \"coord\": xarray.DataArray(\n                numpy.arange(10, dtype=float), dims=(\"coord\",), attrs=attrs\n            ),\n        }\n        data_vars = {\n            \"data_var_simple\": ((\"coord2\",), numpy.zeros(5, dtype=numpy.float32)),\n            \"data_var\": ((\"coord\",), numpy.zeros(10, dtype=complex), attrs),\n            \"extra_data_var\": ((\"coord\",), numpy.ones(10, dtype=int), attrs),\n        }\n        dataset = xarray.Dataset(data_vars, coords, attrs)\n        check_dataset(dataset, TEST_DATASET_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_dataset_extra_datavar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_dataset_optional_coordinate": {
        "code": "class TestSchema:\n    def time_check_dataset_optional_coordinate(self):\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345}\n        coords = {\n            \"coord\": xarray.DataArray(\n                numpy.arange(10, dtype=float), dims=(\"coord\",), attrs=attrs\n            ),\n        }\n        data_vars = {\n            \"data_var\": ((\"coord\",), numpy.zeros(10, dtype=complex), attrs),\n        }\n        dataset = xarray.Dataset(data_vars, coords, attrs)\n        check_dataset(dataset, TEST_DATASET_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_dataset_optional_coordinate",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_dataset_optional_datavar": {
        "code": "class TestSchema:\n    def time_check_dataset_optional_datavar(self):\n        attrs = {\"attr1\": \"str\", \"attr2\": 123, \"attr3\": 345}\n        coords = {\n            \"coord\": xarray.DataArray(\n                numpy.arange(10, dtype=float), dims=(\"coord\",), attrs=attrs\n            ),\n            \"coord2\": numpy.arange(5, dtype=int),\n        }\n        data_vars = {\n            \"data_var\": ((\"coord\",), numpy.zeros(10, dtype=complex), attrs),\n        }\n        dataset = xarray.Dataset(data_vars, coords, attrs)\n        check_dataset(dataset, TEST_DATASET_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_dataset_optional_datavar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_dict": {
        "code": "class TestSchema:\n    def time_check_dict(self):\n        data = {\"attr1\": \"asd\", \"attr2\": 234, \"attr3\": 345}\n        issues = check_dict(data, TEST_DICT_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_dict",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_dict_constructor": {
        "code": "class TestSchema:\n    def time_check_dict_constructor(self):\n        data = _TestDictSchema(attr1=\"asd\", attr2=234, attr3=345)\n        issues = check_dict(data, TEST_DICT_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_dict_constructor",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_dict_constructor_defaults": {
        "code": "class TestSchema:\n    def time_check_dict_constructor_defaults(self):\n        data = _TestDictSchema(attr1=\"asd\")\n        issues = check_dict(data, TEST_DICT_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_dict_constructor_defaults",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_check_dict_optional": {
        "code": "class TestSchema:\n    def time_check_dict_optional(self):\n        data = {\"attr1\": \"asd\", \"attr2\": 234}\n        issues = check_dict(data, TEST_DICT_SCHEMA)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_check_dict_optional",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_schema_export": {
        "code": "class TestSchema:\n    def time_schema_export(self):\n        export_schema_json_file(_TestDatasetSchema, \"benchmark_schema_export.json\")\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_schema_export",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_schema_import": {
        "code": "class TestSchema:\n    def time_schema_import(self):\n        # Import the schema file exported once in ``setup_cache``.\n        import_schema_json_file(\"test_dataset_schema.json\")\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_schema_import",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_xarray_dataclass_to_array_schema": {
        "code": "class TestSchema:\n    def time_xarray_dataclass_to_array_schema(self):\n        xarray_dataclass_to_array_schema(_TestArraySchema)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_xarray_dataclass_to_array_schema",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_xarray_dataclass_to_dataset_schema": {
        "code": "class TestSchema:\n    def time_xarray_dataclass_to_dataset_schema(self):\n        xarray_dataclass_to_dataset_schema(_TestDatasetSchema)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_xarray_dataclass_to_dataset_schema",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "schema.TestSchema.time_xarray_dataclass_to_dict_schema": {
        "code": "class TestSchema:\n    def time_xarray_dataclass_to_dict_schema(self):\n        xarray_dataclass_to_dict_schema(_TestDictSchema)\n\n    def setup_cache(self):\n        # Export schema for import test.\n        #\n        # This runs once per environment/commit and writes the schema\n        # JSON to a well-known file. The benchmark itself can then\n        # refer to that file path directly without needing any\n        # additional arguments or cached attributes.\n        export_schema_json_file(_TestDatasetSchema, \"test_dataset_schema.json\")",
        "min_run_count": 2,
        "name": "schema.TestSchema.time_xarray_dataclass_to_dict_schema",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "schema:287",
        "type": "time",
        "unit": "seconds",
        "version": "xradio 1.0.2",
        "warmup_time": -1
    },
    "version": 2
}