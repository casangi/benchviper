{
    "measurement_set.TestLoadProcessingSet.time_basic_load": {
        "code": "class TestLoadProcessingSet:\n    def time_basic_load(self):\n        \"\"\"Test basic loading of processing set without parameters\"\"\"\n        ps_xdt = load_processing_set(self.processing_set)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_basic_load",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:21",
        "type": "time",
        "unit": "seconds",
        "version": "ec59672a58901670783afa587b17afabf689ad3cdd6a3badd098900d34ac1790",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_check_datatree": {
        "code": "class TestLoadProcessingSet:\n    def time_check_datatree(self):\n        \"\"\"Test that the converted MS to PS complies with the datatree schema checker\"\"\"\n        ps_xdt = load_processing_set(self.processing_set)\n        issues = check_datatree(ps_xdt)\n        # The check_datatree function returns a SchemaIssues object, not a string\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_check_datatree",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:21",
        "type": "time",
        "unit": "seconds",
        "version": "3266b2830e4c0b69ac3c071a31a6f95993b3216622285f8472514300fc0e1461",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_data_group_selection": {
        "code": "class TestLoadProcessingSet:\n    def time_data_group_selection(self):\n        \"\"\"Test loading with specific data group\"\"\"\n        ps_xdt = load_processing_set(self.processing_set, data_group_name=\"base\")\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_data_group_selection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:21",
        "type": "time",
        "unit": "seconds",
        "version": "1d4fde2f338b9978b4f8f5e2cfa4d09404d23b379d8c6da42ab0efc882505bcc",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_drop_variable": {
        "code": "class TestLoadProcessingSet:\n    def time_drop_variable(self):\n        \"\"\"Test loading with specific variables dropped\"\"\"\n        # Test dropping specific variable\n        drop_vars = [\"WEIGHT\"]\n        ps_xdt = load_processing_set(self.processing_set, drop_variables=drop_vars)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_drop_variable",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:21",
        "type": "time",
        "unit": "seconds",
        "version": "3eb7e64518604db1df044431eab795f9f50b4696c34f82971d03c61a1f994c0d",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_include_variable": {
        "code": "class TestLoadProcessingSet:\n    def time_include_variable(self):\n        \"\"\"Test loading with specific variables included\"\"\"\n        # Test including specific variable\n        include_vars = [\"VISIBILITY\"]\n        ps_xdt = load_processing_set(\n            self.processing_set,\n            include_variables=include_vars,\n        )\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_include_variable",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:21",
        "type": "time",
        "unit": "seconds",
        "version": "2e1c8ac0ee80c615ac1d998342164795966a960664f26e479d57a8ecd15be8c2",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_selective_loading": {
        "code": "class TestLoadProcessingSet:\n    def time_selective_loading(self):\n        \"\"\"Test loading with selection parameters\"\"\"\n        # First load normally to get MS names\n        full_ps = load_processing_set(self.processing_set)\n    \n        # Check MS names are the expected ones\n        ms_basename = \"Antennae_North.cal.lsrk.split\"\n        expected_names = [f\"{ms_basename}_{i}\" for i in range(4)]  # 0 to 3\n        ms_names = list(full_ps.children.keys())\n    \n        assert len(ms_names) == len(\n            expected_names\n        ), \"Number of measurement sets doesn't match\"\n        for ms_name, expected_name in zip(sorted(ms_names), sorted(expected_names)):\n            assert (\n                ms_name == expected_name\n            ), f\"Expected {expected_name} but got {ms_name}\"\n    \n        # Test loading with selection parameters\n        sel_parms = {ms_name: {\"time\": slice(0, 10)}}\n        ps_xdt = load_processing_set(self.processing_set, sel_parms=sel_parms)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_selective_loading",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:21",
        "type": "time",
        "unit": "seconds",
        "version": "79086f3ed98d0c27fe81237161fede25c8e439dae662382c2cede03979f548f2",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_sub_datasets_false": {
        "code": "class TestLoadProcessingSet:\n    def time_sub_datasets_false(self):\n        \"\"\"Test loading without sub-datasets\"\"\"\n        # Test without sub-datasets\n        ps_without_subs = load_processing_set(\n            self.processing_set, load_sub_datasets=False\n        )\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_sub_datasets_false",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:21",
        "type": "time",
        "unit": "seconds",
        "version": "fe63e45c749326a8f1e97afaa0a15a35cbf2f539021eed8006c9db0b0fb445c9",
        "warmup_time": -1
    },
    "measurement_set.TestLoadProcessingSet.time_sub_datasets_true": {
        "code": "class TestLoadProcessingSet:\n    def time_sub_datasets_true(self):\n        \"\"\"Test loading with sub-datasets\"\"\"\n        # Test with sub-datasets\n        _ps_with_subs = load_processing_set(self.processing_set, load_sub_datasets=True)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )",
        "min_run_count": 2,
        "name": "measurement_set.TestLoadProcessingSet.time_sub_datasets_true",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:21",
        "type": "time",
        "unit": "seconds",
        "version": "3165b4b4ae775388d4f0d739f8d1faee5ab0a2618de618475bf5374da4903f63",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_get_combined_antenna_xds": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_get_combined_antenna_xds(self, ps_xdt):\n        \"\"\"Benchmark getting combined antenna dataset from a processing set\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_combined_antenna_xds()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_get_combined_antenna_xds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:126",
        "type": "time",
        "unit": "seconds",
        "version": "5596d23d966c154df194583f9f19e697b4ee953bff96e43a6ac9413f659275d0",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_get_combined_field_and_source_xds": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_get_combined_field_and_source_xds(self, ps_xdt):\n        \"\"\"Benchmark getting combined field and source dataset from a processing set\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_combined_field_and_source_xds()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_get_combined_field_and_source_xds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:126",
        "type": "time",
        "unit": "seconds",
        "version": "f030a3bf41e5f516c1af47344086a3806983d8d7fe8e04cb6e4648718977b2ee",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_get_freq_axis": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_get_freq_axis(self, ps_xdt):\n        \"\"\"Benchmark getting frequency axis from a processing set\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_freq_axis()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_get_freq_axis",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:126",
        "type": "time",
        "unit": "seconds",
        "version": "8934aa3373cc543d8d51e3dbcf95338a303a3306c37554e9561887d6288ffba3",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_get_max_dims": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_get_max_dims(self, ps_xdt):\n        \"\"\"Benchmark getting maximum dimensions from a processing set\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_max_dims()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_get_max_dims",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:126",
        "type": "time",
        "unit": "seconds",
        "version": "2ca1c5f952d9454f69b543bfd0d2fa23a0b16f60ffeb3fc3e515d02564cde8a0",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_query_by_data_group": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_query_by_data_group(self, ps_xdt):\n        \"\"\"Benchmark querying a processing set by data group\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.query(data_group_name=\"base\")\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_query_by_data_group",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:126",
        "type": "time",
        "unit": "seconds",
        "version": "f6458e0cc2c0b50c39329a401df5eb794715e583bf0cbd6001ee0af4cd300831",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_query_by_name": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_query_by_name(self, ps_xdt):\n        \"\"\"Benchmark querying a processing set by name\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        ms_names = list(ps_xdt.children.keys())\n        ps_xdt.xr_ps.query(name=ms_names[0])\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_query_by_name",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:126",
        "type": "time",
        "unit": "seconds",
        "version": "4d19065839b0e533ef55697afe6dbcdd7849a3d008a3b21d8f67d9066131b654",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_summary": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_summary(self, ps_xdt):\n        \"\"\"Benchmark the summary method on a real processing set\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.summary()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_summary",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:126",
        "type": "time",
        "unit": "seconds",
        "version": "e8e6769b9658995c25d739010e5b16e716075db44f0010b41be43672d6b42ac9",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithData.time_summary_ordered": {
        "code": "class TestProcessingSetXdtWithData:\n    def time_summary_ordered(self, ps_xdt):\n        \"\"\"Benchmark the summary method with first_columns parameter\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.summary(first_columns=[\"spw_name\", \"scan_name\"])\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithData.time_summary_ordered",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:126",
        "type": "time",
        "unit": "seconds",
        "version": "db534d4e5a1bdfc12dfc6eaf6804b4c6fdde662b777e877189e2ea0113cc8980",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithEphemerisData.time_check_datatree": {
        "code": "class TestProcessingSetXdtWithEphemerisData:\n    def time_check_datatree(self, ps_xdt):\n        \"\"\"Benchmark that the converted MS to PS complies with the datatree schema checker\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        check_datatree(ps_xdt)\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithEphemerisData.time_check_datatree",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:213",
        "type": "time",
        "unit": "seconds",
        "version": "9fdc3a53ee5a2e0e8368b4d5f1ae72813e4cea4cbde731c46d0ce432e6837be2",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithEphemerisData.time_field_offset_calculation": {
        "code": "class TestProcessingSetXdtWithEphemerisData:\n    def time_field_offset_calculation(self, ps_xdt):\n        \"\"\"Benchmark that field offsets are correctly calculated\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        field_source_xds = ps_xdt.xr_ps.get_combined_field_and_source_xds_ephemeris()\n        field_offset = field_source_xds[\"FIELD_OFFSET\"]\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithEphemerisData.time_field_offset_calculation",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:213",
        "type": "time",
        "unit": "seconds",
        "version": "37e87d8a304c72352172381244e340384e40101f9d13bde84faa7d2b1c124034",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithEphemerisData.time_get_combined_field_and_source_xds_ephemeris": {
        "code": "class TestProcessingSetXdtWithEphemerisData:\n    def time_get_combined_field_and_source_xds_ephemeris(self, ps_xdt):\n        \"\"\"Benchmark getting combined field and source dataset with ephemeris from a processing set\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        ps_xdt.xr_ps.get_combined_field_and_source_xds_ephemeris()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithEphemerisData.time_get_combined_field_and_source_xds_ephemeris",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:213",
        "type": "time",
        "unit": "seconds",
        "version": "9aef9cfaaf76da86212152a09a0715fc404111b01d66b6e7584ec79b983e5941",
        "warmup_time": -1
    },
    "measurement_set.TestProcessingSetXdtWithEphemerisData.time_time_interpolation": {
        "code": "class TestProcessingSetXdtWithEphemerisData:\n    def time_time_interpolation(self, ps_xdt):\n        \"\"\"Benchmark that time interpolation works correctly for ephemeris data\"\"\"\n        #ps_xdt = load_processing_set(self.processing_set)\n        field_source_xds = ps_xdt.xr_ps.get_combined_field_and_source_xds_ephemeris()\n\n    def setup_cache(self):\n        # perform the expensive operations once (per env, per commit), see\n        # https://asv.readthedocs.io/en/stable/writing_benchmarks.html#setup-and-teardown-functions\n    \n        # adapted from https://github.com/casangi/xradio/blob/main/tests/_utils/conftest.py\n    \n        # download MS from cloudflare using helper module\n        from toolviper.utils.data import download\n    \n        download(file=self.MeasurementSet)\n    \n        # Convert MS to processing set\n        from xradio.measurement_set import convert_msv2_to_processing_set\n    \n        ps_path = self.processing_set\n    \n        convert_msv2_to_processing_set(\n            in_file=self.MeasurementSet,\n            out_file=self.processing_set,\n            partition_scheme=[],\n            main_chunksize=0.01,\n            pointing_chunksize=0.00001,\n            pointing_interpolate=True,\n            ephemeris_interpolate=True,\n            use_table_iter=False,\n            overwrite=True,\n            parallel_mode=\"none\",\n        )\n    \n        # Load the PS in cache to use in every test case\n        return load_processing_set(self.processing_set)",
        "min_run_count": 2,
        "name": "measurement_set.TestProcessingSetXdtWithEphemerisData.time_time_interpolation",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "measurement_set:213",
        "type": "time",
        "unit": "seconds",
        "version": "a7123c5ccc1ca88f1c2eb8d9879f995a9ac5a9de57921fec60131598b34157bf",
        "warmup_time": -1
    },
    "version": 2
}